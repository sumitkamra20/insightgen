{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Logging is now visible in Jupyter Notebook!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "import logging\n",
    "from io import BytesIO\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pptx import Presentation\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "\n",
    "input_dir = \"/Users/sumitkamra/code/sumitkamra20/insightgen/data/input\"\n",
    "output_dir = \"/Users/sumitkamra/code/sumitkamra20/insightgen/data/output\"\n",
    "\n",
    "# Configure logging to display INFO level logs in Jupyter Notebook\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "\n",
    "# Test it\n",
    "logging.info(\"Logging is now visible in Jupyter Notebook!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extract slide metadata and initiatlize a dictionary to store slide metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract slide metadata\n",
    "import os\n",
    "from pptx import Presentation\n",
    "from pptx.enum.shapes import PP_PLACEHOLDER\n",
    "\n",
    "def extract_slide_metadata(input_folder: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts metadata from each slide in a PPTX file.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing the PPTX file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary storing slide metadata including layout, content status, placeholder availability,\n",
    "              and placeholders for observations.\n",
    "    \"\"\"\n",
    "    # Find the PPTX file in the input folder\n",
    "    pptx_files = [f for f in os.listdir(input_folder) if f.endswith('.pptx')]\n",
    "\n",
    "    if not pptx_files:\n",
    "        raise FileNotFoundError(\"No PPTX file found in the input folder.\")\n",
    "    if len(pptx_files) > 1:\n",
    "        raise ValueError(\"Multiple PPTX files found. Please keep only one.\")\n",
    "\n",
    "    pptx_path = os.path.join(input_folder, pptx_files[0])\n",
    "    presentation = Presentation(pptx_path)\n",
    "\n",
    "    slide_data = {}\n",
    "\n",
    "    # Iterate through slides and extract metadata\n",
    "    for slide_number, slide in enumerate(presentation.slides, start=1):\n",
    "        layout_name = slide.slide_layout.name  # Extract layout name\n",
    "\n",
    "        # Mark slide as non-content if its layout name starts with \"HEADER\" (case-insensitive)\n",
    "        content_slide = not layout_name.upper().startswith(\"HEADER\")\n",
    "\n",
    "        # Check if a title placeholder exists (if any shape is a placeholder of type TITLE)\n",
    "        has_placeholder = any(\n",
    "            shape.is_placeholder and shape.placeholder_format.type == PP_PLACEHOLDER.TITLE\n",
    "            for shape in slide.shapes\n",
    "        )\n",
    "\n",
    "        # Initialize empty fields for later functions to fill\n",
    "        slide_data[slide_number] = {\n",
    "            \"layout\": layout_name,\n",
    "            \"content_slide\": content_slide,\n",
    "            \"has_placeholder\": has_placeholder,\n",
    "            \"key_observations\": \"\",\n",
    "            \"slide_headline\": \"\",\n",
    "            \"speaker_notes\": \"\",\n",
    "        }\n",
    "\n",
    "    return slide_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create slide images and store in slide metadata dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def generate_slide_images_base64(input_folder: str, slide_data: dict, img_format=\"JPEG\", dpi=200) -> dict:\n",
    "    \"\"\"\n",
    "    Converts PDF slides to images, encodes them in base64, and updates the slide_data dictionary.\n",
    "    Excludes non-content slides (e.g., Header or Divider) from image processing.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Directory containing input PDF and PPTX files.\n",
    "        slide_data (dict): Dictionary storing slide metadata.\n",
    "        img_format (str): Image format (default: JPEG).\n",
    "        dpi (int): Resolution for image conversion.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated slide metadata dictionary with base64 images (only for content slides).\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\"Starting PDF to image conversion...\")\n",
    "\n",
    "    # Validate input directory\n",
    "    if not os.path.exists(input_folder):\n",
    "        raise ValueError(f\"Input directory does not exist: {input_folder}\")\n",
    "\n",
    "    # Find PDF file in the input folder\n",
    "    pdf_files = [f for f in os.listdir(input_folder) if f.endswith('.pdf')]\n",
    "\n",
    "    if not pdf_files:\n",
    "        logging.error(\"No PDF file found in the input folder.\")\n",
    "        return slide_data\n",
    "\n",
    "    if len(pdf_files) > 1:\n",
    "        logging.error(\"Multiple PDF files found. Please keep only one.\")\n",
    "        return slide_data\n",
    "\n",
    "    pdf_path = os.path.join(input_folder, pdf_files[0])\n",
    "\n",
    "    # Convert PDF to images (in-memory)\n",
    "    images = convert_from_path(pdf_path, dpi=dpi)\n",
    "\n",
    "    logging.info(f\"PDF successfully converted to {len(images)} images.\")\n",
    "\n",
    "    # Process only content slides\n",
    "    for i, image in enumerate(images, start=1):\n",
    "        slide_number = i  # Assuming slides and PDF pages match 1:1\n",
    "\n",
    "        # Skip non-content slides\n",
    "        if slide_number not in slide_data or not slide_data[slide_number][\"content_slide\"]:\n",
    "            slide_data[slide_number][\"status\"] = \"Skipped (Non-content slide)\"\n",
    "            continue\n",
    "\n",
    "        # Convert image to base64 (in-memory)\n",
    "        img_byte_arr = BytesIO()\n",
    "        image.save(img_byte_arr, format=img_format)\n",
    "        img_byte_arr.seek(0)\n",
    "        base64_image = base64.b64encode(img_byte_arr.read()).decode('utf-8')\n",
    "\n",
    "        # Store base64 image in slide_data dictionary\n",
    "        slide_data[slide_number][\"image_base64\"] = base64_image\n",
    "        slide_data[slide_number][\"status\"] = \"Image processed\"\n",
    "\n",
    "        logging.info(f\"Slide {slide_number}: Image converted and stored as base64.\")\n",
    "\n",
    "    logging.info(\"Base64 images stored successfully in slide metadata.\")\n",
    "\n",
    "    return slide_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:Use Vision API and Assistant API for Observations and headlines\n",
    "\n",
    "- Step 1: Generate observations and store in slide metadata\n",
    "- Step 2: Generate headlines through observations and store in slide metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global prompt variables (to be moved to a separate file later if desired)\n",
    "\n",
    "OBSERVATIONS_SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI assistant specialized in analyzing market research report slides.\n",
    "\n",
    "### What You Will Be Provided With:\n",
    "- You will receive an image of a slide that may contain data, charts, and insights from a market research study conducted by Kantar.\n",
    "- The **specific `<category>` and `<market>` will be provided by the user in their prompt.**\n",
    "- The image might include data for different brands across various timeframes, or data for the category or user profiles, etc.\n",
    "- **You might see Kantar and client brand logos at the very bottom of the slide. You can ignore them.**\n",
    "\n",
    "### Instructions:\n",
    "1. **Identify the Slide Topic:**\n",
    "   - Determine what the slide is about based on the label above the charts.\n",
    "\n",
    "2. **Analyze the Data Thoroughly:**\n",
    "   - Carefully **read all the data** and identify notable trends or patterns.\n",
    "   - If the data covers **multiple timeframes**, you **must always** analyze both:\n",
    "     - **Short-term movement** (latest period vs. the preceding period).\n",
    "     - **Long-term movement** (current period vs. the first period available on the slide).\n",
    "     - Ensure both movements are included in your response when applicable. **If either movement is missing, your response is incomplete.**\n",
    "   - If the slide **does not** include a timeframe:\n",
    "     - Compare differences between brands or other labels visible in the slide.\n",
    "\n",
    "3. **Ensure Objectivity and Completeness:**\n",
    "   - **Base your response solely on the factual information** available in the slide.\n",
    "   - Do **not** add any information beyond what is provided in the image.\n",
    "   - **Always check that both short-term and long-term trends are covered if timeframes exist.**\n",
    "\"\"\"\n",
    "\n",
    "HEADLINE_SYSTEM_INSTRUCTIONS = \"\"\"\n",
    "You are an AI assistant specialized in **creating headlines** for Brand Health Tracking reports.\n",
    "\n",
    "### **Task:**\n",
    "You are given a textual description of data in a **brand health tracking slide**.\n",
    "Your job is to **generate a concise headline** that summarizes the main idea with an **implication** for:\n",
    "- **Client brands vs. competitors**, OR\n",
    "- **The category**, OR\n",
    "- **The market** *(depending on the slide content).*\n",
    "\n",
    "#### **Headline Requirements:**\n",
    "- **Length:** 30-50 words.\n",
    "- **Avoid precise numeric figures.**\n",
    "- **Plain text only** (no markdown symbols).\n",
    "- **Use sentence case.**\n",
    "\n",
    "### **Additional User Instructions (if provided):**\n",
    "{additional_system_instructions}\n",
    "\n",
    "### **You Understand:**\n",
    "#### **1. Make Connections Between Measures and Brands**\n",
    "- **Where possible, establish causal links between metrics.**\n",
    "  - Example: **\"Brand Power decline is driven by a drop in Meaningful connection and lower Salience.\"**\n",
    "  - Example: **\"A drop in Salience is reflected in weaker TOM awareness.\"**\n",
    "  - Example: **\"Tiger’s decline in Meaningful connection has strengthened rivals like 333 and Saigon Beer.\"**\n",
    "\n",
    "#### **2. Identify Cross-Slide Insights Where Relevant**\n",
    "- **Slides might be connected**—trends in one slide may explain or be reflected in another.\n",
    "- If applicable, **link insights across slides** to **explain the cause-effect relationship.**\n",
    "  - Example: **\"Brand Power drop among young consumers aligns with weaker endorsement on key brand imageries.\"**\n",
    "\n",
    "#### **3. Kantar’s Brand Power Framework**\n",
    "- **Brand Power**: Core brand equity metric driven by:\n",
    "  - **Meaningful** – Strength of emotional & functional connections.\n",
    "  - **Difference** – Uniqueness and competitive edge.\n",
    "  - **Salience** – How quickly a brand comes to mind in the category, influenced by availability, advertising, and usage.\n",
    "\n",
    "#### **4. Other Key Metrics**\n",
    "- **Brand Image**: Consumer endorsement on brand perceptions, often explaining shifts in Meaningful & Difference.\n",
    "- **Trial & Regular Usage**: Trial is more relevant for smaller brands; regular usage reflects **consumer loyalty**.\n",
    "- **BUMO (Brand Used Most Often)**: Measures **loyal usage base**—critical for big brands.\n",
    "\n",
    "#### **5. Brand Sets & Context**\n",
    "- The user prompt will specify **which brands are client brands and which are competitors**.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "def generate_observations_and_headlines(\n",
    "    slide_data: dict,\n",
    "    user_prompt: str,\n",
    "    additional_system_instructions: str = \"\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    1) Generates textual observations for each content slide using a ChatCompletion call with OBSERVATIONS_SYSTEM_PROMPT.\n",
    "    2) Creates a new Assistant (via the Assistants API) for headlines and calls it to produce a concise headline.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API')\n",
    "    if not openai_api_key:\n",
    "        raise ValueError(\"Missing OPENAI_API key in environment variables.\")\n",
    "\n",
    "    # Initialize the OpenAI client (new format)\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "    # Format the headline system instructions with any additional instructions provided.\n",
    "    formatted_headline_instructions = HEADLINE_SYSTEM_INSTRUCTIONS.format(\n",
    "        additional_system_instructions=additional_system_instructions\n",
    "    )\n",
    "\n",
    "    for slide_number, slide in slide_data.items():\n",
    "        # Process only content slides\n",
    "        if not slide.get(\"content_slide\"):\n",
    "            slide[\"slide_observations\"] = \"\"\n",
    "            slide[\"slide_headline\"] = \"HEADER SLIDE\"\n",
    "            slide[\"status\"] = \"Skipped (Non-content slide)\"\n",
    "            continue\n",
    "\n",
    "        base64_image = slide.get(\"image_base64\", \"\")\n",
    "        if not base64_image:\n",
    "            logging.error(f\"Slide {slide_number}: Missing base64 image.\")\n",
    "            slide[\"slide_observations\"] = \"\"\n",
    "            slide[\"slide_headline\"] = \"Error: Missing slide image\"\n",
    "            slide[\"status\"] = \"Error\"\n",
    "            continue\n",
    "\n",
    "        # ---------------------------\n",
    "        # STEP 1: Generate Observations via ChatCompletion (updated format)\n",
    "        # ---------------------------\n",
    "        try:\n",
    "            obs_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                temperature=0.6,\n",
    "                max_tokens=4000,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": OBSERVATIONS_SYSTEM_PROMPT},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": f\"(Slide {slide_number}) {user_prompt}\"},\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                                    \"detail\": \"high\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            observations_text = obs_response.choices[0].message.content.strip()\n",
    "            slide[\"slide_observations\"] = observations_text\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Slide {slide_number}: Error generating observations: {str(e)}\")\n",
    "            slide[\"slide_observations\"] = \"Error in observations generation\"\n",
    "            slide[\"slide_headline\"] = \"\"\n",
    "            slide[\"status\"] = \"Error\"\n",
    "            continue\n",
    "\n",
    "        # ---------------------------\n",
    "        # STEP 2: Generate Headline via Assistants API\n",
    "        # ---------------------------\n",
    "        try:\n",
    "            headline_assistant = client.beta.assistants.create(\n",
    "                name=\"Headline Assistant API\",\n",
    "                instructions=formatted_headline_instructions,\n",
    "                model=\"gpt-4o\",\n",
    "                temperature=0.7\n",
    "            )\n",
    "\n",
    "            thread = client.beta.threads.create()\n",
    "\n",
    "            # Modify the message format to be more direct\n",
    "            user_headline_message = f\"Generate a headline based on these observations:\\n{observations_text}\"\n",
    "\n",
    "            client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=user_headline_message\n",
    "            )\n",
    "\n",
    "            run = client.beta.threads.runs.create_and_poll(\n",
    "                thread_id=thread.id,\n",
    "                assistant_id=headline_assistant.id\n",
    "            )\n",
    "\n",
    "            if run.status == \"completed\":\n",
    "                messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "                final_assistant_msg = messages.data[0]  # Get the most recent message\n",
    "\n",
    "                # Extract only the assistant's response, removing any echoed input\n",
    "                headline = final_assistant_msg.content[0].text.value.strip()\n",
    "\n",
    "                # Clean up the headline by removing any \"Assistant:\" prefix and extra whitespace\n",
    "                headline = headline.replace(\"Assistant:\", \"\").strip()\n",
    "\n",
    "                slide[\"slide_headline\"] = headline\n",
    "                slide[\"status\"] = \"Headline generated\"\n",
    "            else:\n",
    "                slide[\"slide_headline\"] = f\"Error: Run status: {run.status}\"\n",
    "                slide[\"status\"] = f\"Run incomplete ({run.status})\"\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Slide {slide_number}: Error generating headline: {str(e)}\")\n",
    "            slide[\"slide_headline\"] = \"Error in headline generation\"\n",
    "            slide[\"status\"] = \"Error\"\n",
    "\n",
    "    return slide_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Insert slide headlines and observations into the PPTX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pptx import Presentation\n",
    "from pptx.enum.shapes import PP_PLACEHOLDER\n",
    "\n",
    "def insert_headlines_into_pptx(input_folder: str, output_folder: str, slide_data: dict, save_as_new: bool = True):\n",
    "    \"\"\"\n",
    "    Inserts AI-generated headlines into slide title placeholders and observations into speaker notes.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing the input PPTX file.\n",
    "        output_folder (str): Path to the folder where the modified PPTX file should be saved.\n",
    "        slide_data (dict): Dictionary storing slide metadata, headlines, and observations.\n",
    "        save_as_new (bool): Whether to save as a new file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved PowerPoint file.\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting headline and observations insertion into PowerPoint...\")\n",
    "\n",
    "    pptx_files = [f for f in os.listdir(input_folder) if f.endswith('.pptx')]\n",
    "    if not pptx_files:\n",
    "        raise FileNotFoundError(\"No PPTX file found in the input folder.\")\n",
    "    if len(pptx_files) > 1:\n",
    "        raise ValueError(\"Multiple PPTX files found. Please keep only one.\")\n",
    "\n",
    "    pptx_path = os.path.join(input_folder, pptx_files[0])\n",
    "    presentation = Presentation(pptx_path)\n",
    "\n",
    "    for slide_number, slide in enumerate(presentation.slides, start=1):\n",
    "        slide_info = slide_data.get(slide_number, {})\n",
    "        headline = slide_info.get(\"slide_headline\", \"\")\n",
    "        observations = slide_info.get(\"slide_observations\", \"\")\n",
    "\n",
    "        if not headline or headline == \"HEADER SLIDE\":\n",
    "            logging.info(f\"Slide {slide_number}: Skipped (Header or non-content slide)\")\n",
    "            continue\n",
    "\n",
    "        # Update title placeholder with headline\n",
    "        title_updated = False\n",
    "        for shape in slide.shapes:\n",
    "            if shape.is_placeholder and shape.placeholder_format.type == PP_PLACEHOLDER.TITLE:\n",
    "                shape.text = headline\n",
    "                title_updated = True\n",
    "                logging.info(f\"Slide {slide_number}: Title updated with headline.\")\n",
    "                break\n",
    "\n",
    "        if not title_updated:\n",
    "            logging.warning(f\"Slide {slide_number}: No title placeholder found for headline.\")\n",
    "\n",
    "        # Add observations to speaker notes\n",
    "        if observations:\n",
    "            notes_slide = slide.notes_slide\n",
    "            notes_slide.notes_text_frame.text = observations\n",
    "            logging.info(f\"Slide {slide_number}: Observations added to speaker notes.\")\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Save the modified presentation\n",
    "    original_filename = os.path.basename(pptx_path)\n",
    "    new_filename = original_filename.replace(\".pptx\", \"_WITH_HEADLINES.pptx\")\n",
    "    new_pptx_path = os.path.join(output_folder, new_filename)\n",
    "\n",
    "    presentation.save(new_pptx_path)\n",
    "    logging.info(f\"PowerPoint file saved with headlines and observations: {new_pptx_path}\")\n",
    "\n",
    "    return new_pptx_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Running the code: With 2 Step Preccess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting PDF to image conversion...\n",
      "INFO:root:PDF successfully converted to 10 images.\n",
      "INFO:root:Slide 3: Image converted and stored as base64.\n",
      "INFO:root:Slide 5: Image converted and stored as base64.\n",
      "INFO:root:Slide 6: Image converted and stored as base64.\n",
      "INFO:root:Slide 7: Image converted and stored as base64.\n",
      "INFO:root:Slide 8: Image converted and stored as base64.\n",
      "INFO:root:Slide 9: Image converted and stored as base64.\n",
      "INFO:root:Slide 10: Image converted and stored as base64.\n",
      "INFO:root:Base64 images stored successfully in slide metadata.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_6foZpeFUNo8USwROc5v24WGC/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_6foZpeFUNo8USwROc5v24WGC/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_6foZpeFUNo8USwROc5v24WGC/runs/run_68YLYFBjRcQaER6eXtJVH4uf \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_6foZpeFUNo8USwROc5v24WGC/runs/run_68YLYFBjRcQaER6eXtJVH4uf \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_6foZpeFUNo8USwROc5v24WGC/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_BPYWHb0O2S5XnBcx1dmWZMuv/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_BPYWHb0O2S5XnBcx1dmWZMuv/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_BPYWHb0O2S5XnBcx1dmWZMuv/runs/run_YDihyqTv4JF8gjcixWvfSfdt \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_BPYWHb0O2S5XnBcx1dmWZMuv/runs/run_YDihyqTv4JF8gjcixWvfSfdt \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_BPYWHb0O2S5XnBcx1dmWZMuv/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_WlXi7JbZrrEWwW7mIuFCfE2k/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_WlXi7JbZrrEWwW7mIuFCfE2k/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_WlXi7JbZrrEWwW7mIuFCfE2k/runs/run_oojhawfZntppWUcKwBzSEFlB \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_WlXi7JbZrrEWwW7mIuFCfE2k/runs/run_oojhawfZntppWUcKwBzSEFlB \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_WlXi7JbZrrEWwW7mIuFCfE2k/runs/run_oojhawfZntppWUcKwBzSEFlB \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_WlXi7JbZrrEWwW7mIuFCfE2k/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_jRoldlXkYX2SNWTGqJKnE9iM/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_jRoldlXkYX2SNWTGqJKnE9iM/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_jRoldlXkYX2SNWTGqJKnE9iM/runs/run_XRWGelgJ3wMerunlCoE8K9Cd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_jRoldlXkYX2SNWTGqJKnE9iM/runs/run_XRWGelgJ3wMerunlCoE8K9Cd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_jRoldlXkYX2SNWTGqJKnE9iM/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_PCyGWsFjTpJgwm32SwlGEApl/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_PCyGWsFjTpJgwm32SwlGEApl/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_PCyGWsFjTpJgwm32SwlGEApl/runs/run_9dLX7VskSzg6FyTzhZr7dSxf \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_PCyGWsFjTpJgwm32SwlGEApl/runs/run_9dLX7VskSzg6FyTzhZr7dSxf \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_PCyGWsFjTpJgwm32SwlGEApl/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_lhrMliwFndg1ATQ6Qe7CBjAr/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_lhrMliwFndg1ATQ6Qe7CBjAr/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_lhrMliwFndg1ATQ6Qe7CBjAr/runs/run_5cKY0TiU1yQovy2zjzR2XpuR \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_lhrMliwFndg1ATQ6Qe7CBjAr/runs/run_5cKY0TiU1yQovy2zjzR2XpuR \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_lhrMliwFndg1ATQ6Qe7CBjAr/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/assistants \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_TdPdhlpFlTJ75T1q3TKNcg0D/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/threads/thread_TdPdhlpFlTJ75T1q3TKNcg0D/runs \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_TdPdhlpFlTJ75T1q3TKNcg0D/runs/run_hUzgmv0YCdU5In0Md3MJKhGV \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_TdPdhlpFlTJ75T1q3TKNcg0D/runs/run_hUzgmv0YCdU5In0Md3MJKhGV \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/threads/thread_TdPdhlpFlTJ75T1q3TKNcg0D/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Starting headline and observations insertion into PowerPoint...\n",
      "INFO:root:Slide 1: Skipped (Header or non-content slide)\n",
      "INFO:root:Slide 2: Skipped (Header or non-content slide)\n",
      "INFO:root:Slide 3: Title updated with headline.\n",
      "INFO:root:Slide 3: Observations added to speaker notes.\n",
      "INFO:root:Slide 4: Skipped (Header or non-content slide)\n",
      "INFO:root:Slide 5: Title updated with headline.\n",
      "INFO:root:Slide 5: Observations added to speaker notes.\n",
      "INFO:root:Slide 6: Title updated with headline.\n",
      "INFO:root:Slide 6: Observations added to speaker notes.\n",
      "INFO:root:Slide 7: Title updated with headline.\n",
      "INFO:root:Slide 7: Observations added to speaker notes.\n",
      "INFO:root:Slide 8: Title updated with headline.\n",
      "INFO:root:Slide 8: Observations added to speaker notes.\n",
      "INFO:root:Slide 9: Title updated with headline.\n",
      "INFO:root:Slide 9: Observations added to speaker notes.\n",
      "INFO:root:Slide 10: Title updated with headline.\n",
      "INFO:root:Slide 10: Observations added to speaker notes.\n",
      "INFO:root:PowerPoint file saved with headlines and observations: /Users/sumitkamra/code/sumitkamra20/insightgen/data/output/Tiger Deck for Testing_WITH_HEADLINES.pptx\n"
     ]
    }
   ],
   "source": [
    "# Metadata extraction and image generation\n",
    "slide_metadata = extract_slide_metadata(input_dir)\n",
    "slide_metadata = generate_slide_images_base64(input_dir, slide_metadata)\n",
    "\n",
    "# Headline generation (using the new two-step function)\n",
    "user_prompt = \"\"\"\n",
    "Market: Vietnam,\n",
    "Client brands: Heineken, Tiger, Bia Viet, Larue, Bivina\n",
    "Competitors: 333, Saigon Beer, Hanoi Beer\n",
    "\n",
    "\"\"\"\n",
    "slide_metadata = generate_observations_and_headlines(slide_metadata, user_prompt)\n",
    "\n",
    "# Insert slide headlines into the PPTX file\n",
    "modified_pptx = insert_headlines_into_pptx(input_dir, output_dir, slide_metadata, save_as_new=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insightgen_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
